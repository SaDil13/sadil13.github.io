---
layout: archive
title: "CV"
permalink: /cv/
author_profile: true
redirect_from:
  - /resume
---

{% include base_path %}
<br/>

# Education

- 09/2024 ~ Present: [School of Intelligent Systems Engineering](https://ise.sysu.edu.cn/ "APMA, Brown"){:target="_blank"}, [Sun Yat-sen University](https://www.sysu.edu.cn/ "Brown"){:target="_blank"}
  - M.Eng. in *Control Science and Engineering* (Advisor: Prof. [Xiaodan Liang](https://scholar.google.com/citations?user=voxznZAAAAAJ&hl))
- 09/2020 ~ 06/2024: [School of Intelligent Systems Engineering](https://ise.sysu.edu.cn/ "SCGY, USTC"){:target="_blank"}, [Sun Yat-sen University](https://www.sysu.edu.cn/ "USTC"){:target="_blank"}
  - B.Sc. in *Intelligent Science and Technology* (GPA: 4.03/5.0, Ranking: 3/226)

<br/>
<br/>

# Publications and Preprints

<div class="publication row clearfix">
    <div class="row-text">
        <a class="publication-title bold" href="https://arxiv.org/abs/2505.20148">MineAnyBuild: Benchmarking Spatial Planning for Open-world AI Agents</a><br/>
        <span class="bold"><b>Ziming Wei</b></span><sup title="Equal Contribution">*</sup>, Bingqian Lin<sup title="Equal Contribution">*</sup>, Zijian Jiao<sup title="Equal Contribution">*</sup>, Yunshuang Nie, Liang Ma, Yuecheng Liu, Yuzheng Zhuang, Xiaodan Liang<sup title="Corresponding Author">&dagger;</sup><br/>
        <a class="btn btn-dark" href="https://mineanybuild.github.io/">project</a> / <a class="btn btn-red" href="https://arxiv.org/abs/2505.20148">arXiv</a> / <a class="btn" href="https://github.com/MineAnyBuild/MineAnyBuild">code</a> / <a class="btn btn-dark" href="https://huggingface.co/datasets/SaDil/MineAnyBuild">dataset</a>
    </div>
</div>
<br/>
<div class="publication row clearfix">
    <div class="row-text">
        <a class="publication-title bold" href="https://arxiv.org/abs/2503.18065">Unseen from Seen: Rewriting Observation-Instruction Using Foundation Models for Augmenting Vision-Language Navigation</a><br/>
        <span class="bold"><b>Ziming Wei</b></span><sup title="Equal Contribution">*</sup>, Bingqian Lin<sup title="Equal Contribution">*</sup>, Yunshuang Nie, Jiaqi Chen, Shikui Ma, Hang Xu, Xiaodan Liang<sup title="Corresponding Author">&dagger;</sup><br/>
        <!-- <span class="italic">TNNLS</span>, 2025<br/> -->
        <span class="italic">(Under Review</span>)<br/>
        <a class="btn btn-red" href="https://arxiv.org/abs/2503.18065">arXiv</a> / <a class="btn" href="https://github.com/SaDil13/VLN-RAM">code</a>
         <!-- / <a class="btn btn-dark" href="google scholar website">bibtex</a> -->
    </div>
</div>
<br/>
<div class="publication row clearfix">
    <div class="row-text">
        <a class="publication-title bold" href="https://arxiv.org/abs/2403.07376">NavCoT: Boosting LLM-Based Vision-and-Language Navigation via Learning Disentangled Reasoning</a><br/>
        <span class="bold">Bingqian Lin</span><sup title="Equal Contribution">*</sup>, Yunshuang Nie<sup title="Equal Contribution">*</sup>, <b>Ziming Wei</b>, Jiaqi Chen, Shikui Ma, Jianhua Han, Hang Xu, Xiaojun Chang, Xiaodan Liang<sup title="Corresponding Author">&dagger;</sup><br/>
        <span class="italic">(TPAMI</span>, 2025)<br/>
        <a class="btn btn-red" href="https://arxiv.org/abs/2403.07376">arXiv</a> / <a class="btn" href="https://github.com/expectorlin/NavCoT">code</a> / <a class="btn btn-dark" href="https://scholar.googleusercontent.com/scholar.bib?q=info:4eMBD5Yhe-kJ:scholar.google.com/&output=citation&scisdr=ClFwuykLEMfL2NuBElg:AFWwaeYAAAAAZn-HCli5EWPUUsvz76wDLMbWjvw&scisig=AFWwaeYAAAAAZn-HClJR8L5hT8rfLMtHijkmTAw&scisf=4&ct=citation&cd=-1&hl=zh-CN">bibtex</a>
    </div>
</div>
<br/>
<div class="publication row clearfix">
    <div class="row-text">
        <a class="publication-title bold" href="https://arxiv.org/abs/2405.18721">Correctable Landmark Discovery via Large Models for Vision-Language Navigation</a><br/>
        <span class="bold">Bingqian Lin</span><sup title="Equal Contribution">*</sup>, Yunshuang Nie<sup title="Equal Contribution">*</sup>, <b>Ziming Wei</b>, Yi Zhu, Hang Xu, Shikui Ma, Jianzhuang Liu, Xiaodan Liang<sup title="Corresponding Author">&dagger;</sup><br/>
        <span class="italic">(TPAMI</span>, 2024)<br/>
        <a class="btn btn-red" href="https://arxiv.org/abs/2405.18721">arXiv</a> / <a class="btn" href="https://github.com/expectorlin/CONSOLE">code</a> / <a class="btn" href="https://scholar.googleusercontent.com/scholar.bib?q=info:aawz8As7-isJ:scholar.google.com/&output=citation&scisdr=ClFwuykLEMfL2NuDsYU:AFWwaeYAAAAAZn-FqYWKr6syabehBLI4bnvP60M&scisig=AFWwaeYAAAAAZn-FqdvwYHbg-gzrdzg3XjfXGqY&scisf=4&ct=citation&cd=-1&hl=zh-CN">bibtex</a> 
    </div>
</div>

<br/>
<br/>

# Experience

- Research Intern, Huawei Noah's Ark Lab(诺亚方舟实验室), 2025.04-Present
- Research Intern, Tencent SSV ForGood Labs(向善实验室群), 2023.07-2023.11

<br/>
<br/>

# Honors and Awards

- Excellent Bachelar Dissertation Award of Sun Yat-sen University, in 2024 ([Top 1 Recommended](https://ise.sysu.edu.cn/article/992))
- First Class Award Scholarship of the Graduate School, Sun Yat-sen University, in 2024
- The Third Award Scholarship of Sun Yat-sen University Excellent Student, Sun Yat-sen University, China, in 2020-2021, 2021-2022 and 2022-2023
